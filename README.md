ReasoningPortfolio3: Optimal Blackjack Strategy with Reinforcement Learning

Overview

This project investigates the use of reinforcement learning (RL) techniques to develop an optimal strategy for playing blackjack. It includes implementations of various RL algorithms such as Q-learning and Monte Carlo control, integrated with traditional strategies and card counting techniques. The accompanying Jupyter notebook provides the code and results discussed in the research paper "Application of Reinforcement Learning to Develop an Optimal Blackjack Strategy."

Repository Structure
AniketPortfolio3.ipynb: Jupyter notebook containing the implementation, experiments, and analysis.
Setup

Prerequisites
Python 3.6 or higher
Jupyter Notebook

Clone the Repository
Clone the repository:

bash
Copy code
git clone https://github.com/anikerry/ReasoningPortfolio3.git

cd ReasoningPortfolio3
Create a Virtual Environment
Create a virtual environment and activate it:

bash
Copy code
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`

Install Dependencies
Install the required packages:

bash
Copy code
pip install -r requirements.txt

Usage
Running the Jupyter Notebook
To run the notebook, ensure that you have Jupyter installed. If not, you can install it using:

bash
Copy code
pip install jupyter
Then, start the Jupyter notebook server:

bash
Copy code
jupyter notebook
Open the AniketPortfolio3.ipynb notebook in the browser and run the cells to execute the code and see the results.

Results
The results of the experiments are discussed in detail within the notebook. Figures and tables generated from the experiments are embedded in the notebook cells.

Contributing
Contributions are welcome! Please fork the repository and submit a pull request with your changes.

License
This project is licensed under the MIT License. See the LICENSE file for details.

References
[1] E. O. Thorp, Beat the Dealer, New York, NY: Vintage, 1966. Link.
[2] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction,
2nd ed., Cambridge, MA: MIT Press, 2018. Link.
[3] B. Widrow, M. A. Lehr, and M. A. Ercegovac, ”Adaptive Learning
Algorithms for Blackjack Strategy,” IEEE Transactions on Systems,
Man, and Cybernetics, vol. SMC-3, no. 4, pp. 328–336, Jul. 1973.
[4] G. Tesauro, ”Temporal Difference Learning and TD-Gammon,” Communications
of the ACM, vol. 38, no. 3, pp. 58–68, Mar. 1994.
[5] A. Perez-Uribe and E. Sanchez, ”Blackjack as a Test Bed for Learning
Strategies in Neural Networks,” Swiss Federal Institute of Technology,
Lausanne, 1998. Link.
[6] G. Kendall and C. Smith, ”The Evolution of Blackjack Strategies,”
University of Nottingham, 2003. Link.
[7] D. Granville, ”Applying Reinforcement Learning to Blackjack Using
Q-Learning,” Semantic Scholar, 2005. Link.
[8] ”Optimizing Blackjack Strategy with Reinforcement Learning,” Stanford
University, 2020. Link.
[9] ”Reinforcement Learning Strategies Using Monte Carlo Methods,” 2024.
Link.
[10] A. Arutyunov, ”Win at Blackjack with Reinforcement Learning,”
Medium, 30-Dec-2022. Link.

Author
Aniket Dattatraya Kulkarni

Beacons: https://beacons.ai/aniketkulkarni15
ORCID: https://orcid.org/0000-0002-3491-1115
IEEE Author Profile: https://ieeexplore.ieee.org/author/37089687713

